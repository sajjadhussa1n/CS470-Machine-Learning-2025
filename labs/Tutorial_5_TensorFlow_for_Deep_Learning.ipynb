{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to TensorFlow\n",
        "TensorFlow is an end-to-end open-source platform for machine learning developed by Google. It provides a comprehensive ecosystem of tools, libraries, and community resources that lets researchers and developers easily build and deploy ML-powered applications."
      ],
      "metadata": {
        "id": "BFy-ztT_oDdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why TensorFlow?\n",
        "- Production Ready: Robust and scalable for production environments\n",
        "\n",
        "- Flexibility: From research to production with the same framework\n",
        "\n",
        "- Keras Integration: High-level API for fast prototyping\n",
        "\n",
        "- Cross-Platform: Run on CPU, GPU, TPU, mobile, and web\n",
        "\n",
        "- TensorBoard: Powerful visualization toolkit\n",
        "\n",
        "- Large Community: Extensive documentation and support"
      ],
      "metadata": {
        "id": "mFIf-3GXoLeI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Components:\n",
        "- Tensors: Multi-dimensional arrays with automatic differentiation\n",
        "\n",
        "- Keras API: High-level neural networks API\n",
        "\n",
        "- Eager Execution: Imperative programming environment\n",
        "\n",
        "- Distribution Strategies: Training across multiple GPUs/devices\n",
        "\n",
        "- SavedModel: Universal format for saving models"
      ],
      "metadata": {
        "id": "0aYWvdfWoWwm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensorFlow vs PyTorch:\n",
        "- TensorFlow: Better for production, more structured, excellent deployment tools\n",
        "\n",
        "- PyTorch: More Pythonic, better for research, dynamic computation graphs"
      ],
      "metadata": {
        "id": "_epqFrijoiaZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation and Setup"
      ],
      "metadata": {
        "id": "n6pvsQcIoo1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "otXUu2_dotMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"Keras version: {tf.keras.__version__}\")"
      ],
      "metadata": {
        "id": "VW7-NttM502e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU availability\n",
        "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
        "print(f\"TensorFlow built with CUDA: {tf.test.is_built_with_cuda()}\")\n",
        "\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"GPU device name:\", tf.test.gpu_device_name())\n",
        "else:\n",
        "    print(\"No GPU found, using CPU\")"
      ],
      "metadata": {
        "id": "knRTRRpu5yJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensorFlow Tensors: The Fundamental Data Structure\n",
        "Tensors are the central unit of data in TensorFlow. A tensor is a generalization of vectors and matrices to potentially higher dimensions."
      ],
      "metadata": {
        "id": "LJu9QFJNoxpK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Creation and Basic Properties"
      ],
      "metadata": {
        "id": "zmjijs0Io3uO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Tensor Creation and Properties ===\")"
      ],
      "metadata": {
        "id": "dGR-AJId7bwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating tensors from Python lists\n",
        "scalar = tf.constant(5)                    # 0-dimensional tensor (scalar)\n",
        "print(f\"Scalar: {scalar.numpy()}\")"
      ],
      "metadata": {
        "id": "mlxUERAdo74e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector = tf.constant([1, 2, 3, 4])         # 1-dimensional tensor (vector)\n",
        "print(f\"Vector: {vector.numpy()}\")"
      ],
      "metadata": {
        "id": "XJu2cDP67TdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = tf.constant([[1, 2], [3, 4]])     # 2-dimensional tensor (matrix)\n",
        "print(f\"Matrix:\\n{matrix.numpy()}\")"
      ],
      "metadata": {
        "id": "KESD7k5M7TRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_3d = tf.constant([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])  # 3D tensor\n",
        "print(f\"3D Tensor:\\n{tensor_3d.numpy()}\")"
      ],
      "metadata": {
        "id": "qjhFW2lf7SZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor properties\n",
        "print(f\"Shape: {matrix.shape}\")"
      ],
      "metadata": {
        "id": "SCVcoShFpFFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Rank: {tf.rank(matrix).numpy()}\")  # Number of dimensions"
      ],
      "metadata": {
        "id": "6Utzz4IV7qC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Size: {tf.size(matrix).numpy()}\")  # Total number of elements"
      ],
      "metadata": {
        "id": "68Cgxu1p7phg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Data type: {matrix.dtype}\")"
      ],
      "metadata": {
        "id": "WRllzNO_7pXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Device: {matrix.device}\")"
      ],
      "metadata": {
        "id": "5fL9GDbk7pLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Special tensors\n",
        "zeros = tf.zeros([2, 3])                    # 2x3 matrix of zeros\n",
        "print(f\"\\nZeros:\\n{zeros.numpy()}\")"
      ],
      "metadata": {
        "id": "OjyqVBBDpA5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ones = tf.ones([3, 2])                      # 3x2 matrix of ones\n",
        "print(f\"Ones:\\n{ones.numpy()}\")"
      ],
      "metadata": {
        "id": "mAa_ZSCt641o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eye = tf.eye(3)                             # 3x3 identity matrix\n",
        "print(f\"Identity:\\n{eye.numpy()}\")"
      ],
      "metadata": {
        "id": "H02Dc-fj64iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_normal = tf.random.normal(shape=[2, 2], mean=0.0, stddev=1.0)    # 2x2 matrix from normal distribution\n",
        "print(f\"Random Normal:\\n{random_normal.numpy()}\")"
      ],
      "metadata": {
        "id": "SzJvcIDc64Jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_uniform = tf.random.uniform(shape=[2, 2], minval=0, maxval=10, dtype=tf.float32)  # 2x2 matrix from uniform distribution\n",
        "print(f\"Random Uniform:\\n{random_uniform.numpy()}\")"
      ],
      "metadata": {
        "id": "va2nvnsN64AE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Operations and Broadcasting"
      ],
      "metadata": {
        "id": "yzF1q6VepXZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Tensor Operations ===\")\n",
        "\n",
        "# Basic arithmetic operations\n",
        "a = tf.constant([1, 2, 3])\n",
        "b = tf.constant([4, 5, 6])"
      ],
      "metadata": {
        "id": "LmpMwaC5pAx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"a + b: {tf.add(a, b).numpy()}\")        # Element-wise addition\n",
        "print(f\"a - b: {tf.subtract(a, b).numpy()}\")   # Element-wise subtraction\n",
        "print(f\"a * b: {tf.multiply(a, b).numpy()}\")   # Element-wise multiplication\n",
        "print(f\"a / b: {tf.divide(a, b).numpy()}\")     # Element-wise division\n",
        "print(f\"a ** 2: {tf.pow(a, 2).numpy()}\")       # Element-wise power"
      ],
      "metadata": {
        "id": "PE_zPNcFpmMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix operations\n",
        "matrix_a = tf.constant([[1, 2], [3, 4]])\n",
        "matrix_b = tf.constant([[5, 6], [7, 8]])\n",
        "\n",
        "print(f\"\\nMatrix multiplication:\\n{tf.matmul(matrix_a, matrix_b).numpy()}\")"
      ],
      "metadata": {
        "id": "kPLiH5kDpjBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Element-wise multiplication:\\n{tf.multiply(matrix_a, matrix_b).numpy()}\")"
      ],
      "metadata": {
        "id": "d5na_OTJ9jqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduction operations\n",
        "tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
        "print(f\"\\nSum of all elements: {tf.reduce_sum(tensor).numpy()}\")\n",
        "print(f\"Mean of all elements: {tf.reduce_mean(tensor).numpy()}\")\n",
        "print(f\"Max of all elements: {tf.reduce_max(tensor).numpy()}\")\n",
        "print(f\"Sum along rows: {tf.reduce_sum(tensor, axis=0).numpy()}\")\n",
        "print(f\"Sum along columns: {tf.reduce_sum(tensor, axis=1).numpy()}\")"
      ],
      "metadata": {
        "id": "Ip8sM-hIpd8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Broadcasting\n",
        "vector = tf.constant([1, 2])\n",
        "matrix = tf.constant([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "print(f\"\\nBroadcasting example:\")\n",
        "print(f\"Vector: {vector.numpy()}\")\n",
        "print(f\"Matrix:\\n{matrix.numpy()}\")\n",
        "print(f\"Vector + Matrix:\\n{tf.add(vector, matrix).numpy()}\")"
      ],
      "metadata": {
        "id": "qdJKnljlpApM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Reshaping and Manipulation"
      ],
      "metadata": {
        "id": "g3GWg9tAp1wM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--cnEAApi_OX"
      },
      "outputs": [],
      "source": [
        "# Create a 1D tensor\n",
        "original = tf.range(12)\n",
        "print(f\"Original tensor: {original.numpy()}\")\n",
        "print(f\"Original shape: {original.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape operations\n",
        "reshaped_2d = tf.reshape(original, [3, 4])\n",
        "print(f\"\\nReshaped to 3x4:\\n{reshaped_2d.numpy()}\")"
      ],
      "metadata": {
        "id": "XDL3jHKeqAWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_3d = tf.reshape(original, [2, 3, 2])\n",
        "print(f\"\\nReshaped to 2x3x2:\\n{reshaped_3d.numpy()}\")\n",
        "print(f\"Shape: {reshaped_3d.shape}\")"
      ],
      "metadata": {
        "id": "tt9TTUYN-YFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transpose\n",
        "matrix = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
        "print(f\"\\nOriginal matrix:\\n{matrix.numpy()}\")\n",
        "print(f\"Transposed:\\n{tf.transpose(matrix).numpy()}\")"
      ],
      "metadata": {
        "id": "hzP20twhp9YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenation\n",
        "t1 = tf.constant([[1, 2], [3, 4]])\n",
        "t2 = tf.constant([[5, 6], [7, 8]])\n",
        "\n",
        "print(f\"\\nVertical concatenation:\\n{tf.concat([t1, t2], axis=0).numpy()}\")\n",
        "print(f\"Horizontal concatenation:\\n{tf.concat([t1, t2], axis=1).numpy()}\")"
      ],
      "metadata": {
        "id": "eqyimfhyp7NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing and indexing\n",
        "tensor = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "print(f\"\\nOriginal tensor:\\n{tensor.numpy()}\")"
      ],
      "metadata": {
        "id": "hevItuHsp4zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"First row: {tensor[0].numpy()}\")"
      ],
      "metadata": {
        "id": "4hLRc_Cy_Guq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Element at (1,2): {tensor[1, 2].numpy()}\")"
      ],
      "metadata": {
        "id": "chBNZVZa_ALz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"First two rows:\\n{tensor[:2].numpy()}\")"
      ],
      "metadata": {
        "id": "Dp0IG0sz-__p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Last column:\\n{tensor[:, -1].numpy()}\")"
      ],
      "metadata": {
        "id": "KDMdKYJG-_KV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practice Question 1\n",
        "Create and manipulate tensors:\n",
        "\n",
        "1.    Create a 2x4 tensor with values from 1 to 8\n",
        "\n",
        "2.    Reshape it to 4x2\n",
        "\n",
        "3.    Extract the diagonal elements\n",
        "\n",
        "4.    Calculate the mean of all elements\n",
        "\n",
        "5.    Create a boolean mask for elements greater than 4"
      ],
      "metadata": {
        "id": "njSL7qxUqFBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try your solution here\n"
      ],
      "metadata": {
        "id": "RKAnbs4pqkR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try your solution here\n"
      ],
      "metadata": {
        "id": "9_urBNKrqmHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try your solution here\n"
      ],
      "metadata": {
        "id": "Qo-LHNVpqnAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try your solution here\n"
      ],
      "metadata": {
        "id": "QlywlCKYqoZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try your solution here\n"
      ],
      "metadata": {
        "id": "oBKtGtGdqnmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details> <summary>Click to reveal solution</summary>\n",
        "\n",
        "```python\n",
        "\n",
        "# 1. Create 2x4 tensor\n",
        "tensor_2x4 = tf.reshape(tf.range(1, 9), [2, 4])\n",
        "print(f\"1. 2x4 tensor:\\n{tensor_2x4.numpy()}\")\n",
        "\n",
        "# 2. Reshape to 4x2\n",
        "tensor_4x2 = tf.reshape(tensor_2x4, [4, 2])\n",
        "print(f\"\\n2. Reshaped to 4x2:\\n{tensor_4x2.numpy()}\")\n",
        "\n",
        "# 3. Extract diagonal (for square matrices, but we can get main diagonal elements)\n",
        "diagonal = tf.linalg.diag_part(tensor_2x4) if tensor_2x4.shape[0] == tensor_2x4.shape[1] else \"Not a square matrix\"\n",
        "print(f\"\\n3. Diagonal elements: {diagonal}\")\n",
        "\n",
        "# Alternative: Get elements where row == col\n",
        "rows, cols = tensor_2x4.shape\n",
        "diagonal_indices = tf.minimum(rows, cols)\n",
        "diagonal_elements = [tensor_2x4[i, i].numpy() for i in range(diagonal_indices)]\n",
        "print(f\"   Main diagonal elements: {diagonal_elements}\")\n",
        "\n",
        "# 4. Calculate mean\n",
        "mean_value = tf.reduce_mean(tf.cast(tensor_2x4, tf.float32))\n",
        "print(f\"\\n4. Mean of all elements: {mean_value.numpy():.2f}\")\n",
        "\n",
        "# 5. Boolean mask for elements > 4\n",
        "boolean_mask = tensor_2x4 > 4\n",
        "print(f\"\\n5. Boolean mask (elements > 4):\\n{boolean_mask.numpy()}\")\n",
        "print(f\"   Elements greater than 4: {tensor_2x4[boolean_mask].numpy()}\")\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "W0isTW8tqpbg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Automatic Differentiation with GradientTape\n",
        "TensorFlow uses ``GradientTape`` for automatic differentiation - it records operations for automatic differentiation."
      ],
      "metadata": {
        "id": "p0DWvsD8rsBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Gradient Computation\n"
      ],
      "metadata": {
        "id": "GbtVDmbPr1ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple gradient computation\n",
        "x = tf.Variable(3.0)  # Create a trainable variable\n",
        "\n",
        "with tf.GradientTape() as tape: # context manager\n",
        "    y = x ** 2 + 2 * x + 1\n",
        "\n",
        "# Compute gradient of y with respect to x\n",
        "dy_dx = tape.gradient(y, x)\n",
        "print(f\"y = x² + 2x + 1\")\n",
        "print(f\"x = {x.numpy()}\")\n",
        "print(f\"y = {y.numpy()}\")\n",
        "print(f\"dy/dx = {dy_dx.numpy()}\")  # Should be 2x + 2 = 8"
      ],
      "metadata": {
        "id": "FmlZ_ADCq7MI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiple variables\n",
        "print(f\"\\n=== Multiple Variables ===\")\n",
        "w = tf.Variable(2.0)\n",
        "b = tf.Variable(1.0)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    z = w * x + b\n",
        "\n",
        "gradients = tape.gradient(z, [w, b])\n",
        "print(f\"z = w * x + b = {z.numpy()}\")\n",
        "print(f\"dz/dw = {gradients[0].numpy()}\")  # Should be x = 3\n",
        "print(f\"dz/db = {gradients[1].numpy()}\")  # Should be 1"
      ],
      "metadata": {
        "id": "16t_Xj9Yr51U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Complex Computational Graphs"
      ],
      "metadata": {
        "id": "1pdyuty6sClK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Complex Computational Graphs ===\")\n",
        "\n",
        "# More complex function\n",
        "x = tf.Variable(2.0)\n",
        "w = tf.Variable(3.0)\n",
        "b = tf.Variable(1.0)\n",
        "\n",
        "with tf.GradientTape(persistent=True) as tape: # context manager\n",
        "    y = w * tf.sin(x ** 2) + b\n",
        "    z = tf.exp(y) + y ** 2\n",
        "\n",
        "# Compute gradients\n",
        "dy_dx = tape.gradient(y, x)\n",
        "dy_dw = tape.gradient(y, w)\n",
        "dy_db = tape.gradient(y, b)\n",
        "dz_dx = tape.gradient(z, x)\n",
        "\n",
        "print(f\"y = w * sin(x²) + b = {y.numpy():.4f}\")\n",
        "print(f\"z = exp(y) + y² = {z.numpy():.4f}\")\n",
        "print(f\"dy/dx = {dy_dx.numpy():.4f}\")  # w * 2x * cos(x²)\n",
        "print(f\"dy/dw = {dy_dw.numpy():.4f}\")  # sin(x²)\n",
        "print(f\"dy/db = {dy_db.numpy():.4f}\")  # 1\n",
        "print(f\"dz/dx = {dz_dx.numpy():.4f}\")  # dz/dy * dy/dx\n",
        "\n",
        "del tape  # Important for persistent tapes"
      ],
      "metadata": {
        "id": "t7wHOfZzsG7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GradientTape for Machine Learning"
      ],
      "metadata": {
        "id": "AH0SjnVKt3ct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== GradientTape for ML Training ===\")\n",
        "\n",
        "# Simple linear regression example\n",
        "# True parameters\n",
        "true_w = tf.constant(2.0)\n",
        "true_b = tf.constant(1.0)\n",
        "\n",
        "# Generate synthetic data\n",
        "num_samples = 100\n",
        "X = tf.random.normal([num_samples])\n",
        "noise = tf.random.normal([num_samples], stddev=0.1)\n",
        "y = true_w * X + true_b + noise\n",
        "\n",
        "# Trainable variables\n",
        "w = tf.Variable(0.0)\n",
        "b = tf.Variable(0.0)\n",
        "\n",
        "# Training parameters\n",
        "learning_rate = 0.1\n",
        "epochs = 50"
      ],
      "metadata": {
        "id": "7ar5hjPXt5LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training linear regression...\")\n",
        "for epoch in range(epochs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Forward pass\n",
        "        y_pred = w * X + b\n",
        "        # Compute loss (MSE)\n",
        "        loss = tf.reduce_mean(tf.square(y_pred - y))\n",
        "\n",
        "    # Compute gradients\n",
        "    gradients = tape.gradient(loss, [w, b])\n",
        "\n",
        "    # Update parameters\n",
        "    w.assign_sub(learning_rate * gradients[0])\n",
        "    b.assign_sub(learning_rate * gradients[1])\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}: w = {w.numpy():.3f}, b = {b.numpy():.3f}, loss = {loss.numpy():.4f}\")\n",
        "\n",
        "print(f\"\\nFinal parameters: w = {w.numpy():.3f}, b = {b.numpy():.3f}\")\n",
        "print(f\"True parameters: w = {true_w.numpy():.3f}, b = {true_b.numpy():.3f}\")"
      ],
      "metadata": {
        "id": "z6fpfrPlt9qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practice Question 2\n",
        "Implement and compute gradients for:\n",
        "\n",
        "f(x) = x³ - 3x² + x where x=2\n",
        "\n",
        "Multi-variable: L = (w₁x₁ + w₂x₂ + b - y)² where w₁=1, w₂=2, x₁=3, x₂=4, b=1, y=10\n",
        "\n",
        "Chain rule: z = log(1 + exp(wx + b)) where w=2, x=3, b=1"
      ],
      "metadata": {
        "id": "BwWOU92DuP6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try your solution here\n"
      ],
      "metadata": {
        "id": "PyDaO2w7uXF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try your solution here\n"
      ],
      "metadata": {
        "id": "prmkxB3Ruhgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try your solution here\n"
      ],
      "metadata": {
        "id": "lGDAyYZquiAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details> <summary>Click to reveal solution</summary>\n",
        "\n",
        "```python\n",
        "# Solution\n",
        "print(\"=== Practice Question 2 Solution ===\")\n",
        "\n",
        "# 1. f(x) = x³ - 3x² + x\n",
        "x1 = tf.Variable(2.0)\n",
        "with tf.GradientTape() as tape:\n",
        "    f = x1**3 - 3*x1**2 + x1\n",
        "df_dx = tape.gradient(f, x1)\n",
        "print(f\"1. f(x) = x³ - 3x² + x = {f.numpy()}\")\n",
        "print(f\"   df/dx = {df_dx.numpy()} (should be 3x² - 6x + 1 = {3*4 - 6*2 + 1})\")\n",
        "\n",
        "# 2. L = (w₁x₁ + w₂x₂ + b - y)²\n",
        "w1 = tf.Variable(1.0)\n",
        "w2 = tf.Variable(2.0)\n",
        "x1_val = tf.constant(3.0)\n",
        "x2_val = tf.constant(4.0)\n",
        "b = tf.Variable(1.0)\n",
        "y_true = tf.constant(10.0)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    prediction = w1 * x1_val + w2 * x2_val + b\n",
        "    L = (prediction - y_true) ** 2\n",
        "\n",
        "gradients = tape.gradient(L, [w1, w2, b])\n",
        "print(f\"\\n2. L = (w₁x₁ + w₂x₂ + b - y)² = {L.numpy()}\")\n",
        "print(f\"   dL/dw₁ = {gradients[0].numpy()} (should be 2x₁(w₁x₁+w₂x₂+b-y) = {2*3*(1*3+2*4+1-10)} = 12)\")\n",
        "print(f\"   dL/dw₂ = {gradients[1].numpy()} (should be 2x₂(w₁x₁+w₂x₂+b-y) = {2*4*(1*3+2*4+1-10)} = 16)\")\n",
        "print(f\"   dL/db = {gradients[2].numpy()} (should be 2(w₁x₁+w₂x₂+b-y) = {2*(1*3+2*4+1-10)} = 4)\")\n",
        "\n",
        "# 3. z = log(1 + exp(wx + b))\n",
        "w3 = tf.Variable(2.0)\n",
        "x3 = tf.constant(3.0)\n",
        "b3 = tf.Variable(1.0)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    linear = w3 * x3 + b3\n",
        "    z = tf.math.log(1 + tf.math.exp(linear))\n",
        "\n",
        "dz_dw = tape.gradient(z, w3)\n",
        "print(f\"\\n3. z = log(1 + exp(wx + b)) = {z.numpy():.4f}\")\n",
        "print(f\"   dz/dw = {dz_dw.numpy():.4f} (should be x * σ(wx+b) = {3 * (1/(1+tf.math.exp(-(2*3+1)).numpy()):.4f})\")\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "oD5d9gVkui3B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building Neural Networks with Keras\n",
        "Keras is TensorFlow's high-level API for building and training deep learning models. It provides a user-friendly interface while maintaining flexibility."
      ],
      "metadata": {
        "id": "wRD6HB-PvBrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding the Sequential API"
      ],
      "metadata": {
        "id": "W8ayejDqvFz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Building Neural Networks with Keras ===\")\n",
        "\n",
        "# Simplest way: Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(10,)),  # Input layer\n",
        "    tf.keras.layers.Dense(32, activation='relu'),                     # Hidden layer 1\n",
        "    tf.keras.layers.Dense(16, activation='relu'),                     # Hidden layer 2\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')                    # Output layer\n",
        "])"
      ],
      "metadata": {
        "id": "c6X6ChOFuxHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model Architecture:\")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "C-SjHFULvVak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative way to build Sequential model\n",
        "model_alt = tf.keras.Sequential()\n",
        "model_alt.add(tf.keras.layers.Dense(64, activation='relu', input_shape=(10,)))\n",
        "model_alt.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model_alt.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "model_alt.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "PG1AP1PRvNEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nAlternative Model Architecture:\")\n",
        "model_alt.summary()"
      ],
      "metadata": {
        "id": "XLbVgEPlvR65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functional API for Complex Architectures"
      ],
      "metadata": {
        "id": "vjh0ye_IvbbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Functional API for Complex Models ===\")\n",
        "\n",
        "# Functional API allows for more complex architectures\n",
        "inputs = tf.keras.Input(shape=(10,))  # Define input\n",
        "\n",
        "# Create layers\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(inputs)\n",
        "\n",
        "# Branch 1\n",
        "branch1 = tf.keras.layers.Dense(32, activation='relu')(x)\n",
        "branch1 = tf.keras.layers.Dense(16, activation='relu')(branch1)\n",
        "\n",
        "# Branch 2\n",
        "branch2 = tf.keras.layers.Dense(32, activation='tanh')(x)\n",
        "branch2 = tf.keras.layers.Dense(16, activation='tanh')(branch2)\n",
        "\n",
        "# Concatenate branches\n",
        "concatenated = tf.keras.layers.concatenate([branch1, branch2])\n",
        "\n",
        "# Output layer\n",
        "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(concatenated)\n",
        "\n",
        "# Create model\n",
        "functional_model = tf.keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "lOyoQ_lFvfsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Functional Model Architecture:\")\n",
        "functional_model.summary()"
      ],
      "metadata": {
        "id": "UkmLms5Nv9Xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot model architecture\n",
        "tf.keras.utils.plot_model(functional_model, show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "qeUWbI5ev9JR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practice Question 3\n",
        "Build different neural network architectures with input of length 20 for classification:\n",
        "\n",
        "1. Sequential model with 3 hidden layers (128, 64, 32 neurons) for binary classification\n",
        "\n",
        "2. Functional API model with two parallel branches (one branch with 64, 32, 16 neurons, and other branch with 128 and 64 neurons) that merge"
      ],
      "metadata": {
        "id": "1LOhvjnDwIUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try your solution here\n"
      ],
      "metadata": {
        "id": "JYeK5BYFxp4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try your solution here\n"
      ],
      "metadata": {
        "id": "eYAnOhshxrIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details> <summary>Click to reveal solution for part-1</summary>\n",
        "\n",
        "```python\n",
        "# 1. Sequential Model\n",
        "print(\"1. Sequential Model:\")\n",
        "sequential_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(20,)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "sequential_model.summary()\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "m4VG84MhxsbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details> <summary>Click to reveal solution for part-2</summary>\n",
        "\n",
        "```python\n",
        "# 2. Functional API with Parallel Branches\n",
        "print(\"\\n2. Functional API with Parallel Branches:\")\n",
        "inputs = tf.keras.Input(shape=(20,))\n",
        "\n",
        "# Branch 1: Deeper network\n",
        "branch1 = tf.keras.layers.Dense(64, activation='relu')(inputs)\n",
        "branch1 = tf.keras.layers.Dense(32, activation='relu')(branch1)\n",
        "branch1 = tf.keras.layers.Dense(16, activation='relu')(branch1)\n",
        "\n",
        "# Branch 2: Wider but shallower network\n",
        "branch2 = tf.keras.layers.Dense(128, activation='tanh')(inputs)\n",
        "branch2 = tf.keras.layers.Dense(64, activation='tanh')(branch2)\n",
        "\n",
        "# Merge branches\n",
        "merged = tf.keras.layers.concatenate([branch1, branch2])\n",
        "merged = tf.keras.layers.Dropout(0.2)(merged)\n",
        "\n",
        "# Output\n",
        "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(merged)\n",
        "\n",
        "functional_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "functional_model.summary()\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "wvDDbAjzyAKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Compilation and Training"
      ],
      "metadata": {
        "id": "QI8zcNV0yz40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding Loss Functions, Optimizers, and Metrics"
      ],
      "metadata": {
        "id": "_EqXVK_TzBcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Model Compilation ===\")\n",
        "\n",
        "# Create a sample model for demonstration\n",
        "demo_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(10,)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "IZcuIQUNzCxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Different loss functions for different problems\n",
        "print(\"Common Loss Functions:\")\n",
        "print(\"- BinaryCrossentropy: Binary classification\")\n",
        "print(\"- CategoricalCrossentropy: Multi-class classification\")\n",
        "print(\"- SparseCategoricalCrossentropy: Multi-class with integer labels\")\n",
        "print(\"- MeanSquaredError: Regression\")\n",
        "print(\"- MeanAbsoluteError: Regression\")"
      ],
      "metadata": {
        "id": "-9xLa8fX2k-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Different optimizers\n",
        "print(\"\\nCommon Optimizers:\")\n",
        "print(\"- SGD: Stochastic Gradient Descent\")\n",
        "print(\"- Adam: Adaptive Moment Estimation (most popular)\")\n",
        "print(\"- RMSprop: Root Mean Square Propagation\")\n",
        "print(\"- Adagrad: Adaptive Gradient Algorithm\")"
      ],
      "metadata": {
        "id": "PvkPasqy2jEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Common metrics\n",
        "print(\"\\nCommon Metrics:\")\n",
        "print(\"- Accuracy: Classification accuracy\")\n",
        "print(\"- Precision: True positives / (True positives + False positives)\")\n",
        "print(\"- Recall: True positives / (True positives + False negatives)\")\n",
        "print(\"- AUC: Area Under ROC Curve\")\n",
        "print(\"- MAE: Mean Absolute Error (regression)\")\n",
        "print(\"- MSE: Mean Squared Error (regression)\")"
      ],
      "metadata": {
        "id": "ufXJJ57q2gvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "demo_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', 'precision', 'recall']\n",
        ")"
      ],
      "metadata": {
        "id": "AVpb0Jfg2elq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nModel compiled with:\")\n",
        "print(f\"Optimizer: {demo_model.optimizer.get_config()['name']}\")\n",
        "print(f\"Loss: {demo_model.loss}\")"
      ],
      "metadata": {
        "id": "5mpQ5RAsyS3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advanced Optimizer Configuration"
      ],
      "metadata": {
        "id": "Ku8_X7W-2qUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Advanced Optimizer Configuration ===\")\n",
        "\n",
        "# Custom optimizer configuration\n",
        "custom_adam = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001,      # Learning rate\n",
        "    beta_1=0.9,              # Exponential decay rate for 1st moment estimates\n",
        "    beta_2=0.999,            # Exponential decay rate for 2nd moment estimates\n",
        "    epsilon=1e-07,           # Small constant for numerical stability\n",
        "    amsgrad=False            # Whether to apply AMSGrad variant\n",
        ")"
      ],
      "metadata": {
        "id": "dKy7ZF_22v-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_sgd = tf.keras.optimizers.SGD(\n",
        "    learning_rate=0.01,\n",
        "    momentum=0.9,            # Accelerate SGD in relevant direction\n",
        "    nesterov=True            # Nesterov accelerated gradient\n",
        ")"
      ],
      "metadata": {
        "id": "KunjpHjg3M-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate scheduling\n",
        "def learning_rate_schedule(epoch, lr):\n",
        "    \"\"\"Custom learning rate schedule\"\"\"\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * tf.math.exp(-0.1)"
      ],
      "metadata": {
        "id": "lgbXLNfu3KuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Or use built-in schedulers\n",
        "lr_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.01,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True\n",
        ")\n",
        "\n",
        "optimizer_with_scheduler = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)"
      ],
      "metadata": {
        "id": "N_TjYLVy2_uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Complete Training Pipeline"
      ],
      "metadata": {
        "id": "7Dt-OHlU3gkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Complete Training Pipeline ===\")\n",
        "\n",
        "# Generate synthetic dataset for demonstration\n",
        "def generate_synthetic_data(num_samples=1000, input_dim=10):\n",
        "    \"\"\"Generate synthetic binary classification data\"\"\"\n",
        "    X = tf.random.normal([num_samples, input_dim])\n",
        "    # Simple decision boundary: positive if sum of features > 0\n",
        "    y = (tf.reduce_sum(X, axis=1) > 0).numpy().astype(np.float32)\n",
        "    return X.numpy(), y\n",
        "\n",
        "# Generate data\n",
        "X_train, y_train = generate_synthetic_data(1000, 10)\n",
        "X_val, y_val = generate_synthetic_data(200, 10)\n",
        "X_test, y_test = generate_synthetic_data(200, 10)\n",
        "\n",
        "print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Validation data shape: {X_val.shape}, {y_val.shape}\")\n",
        "print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")"
      ],
      "metadata": {
        "id": "CBwLQJcj3kLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and compile model\n",
        "training_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(10,)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "training_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', 'precision', 'recall']\n",
        ")"
      ],
      "metadata": {
        "id": "dnAj8alC4EDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks for enhanced training\n",
        "callbacks = [\n",
        "    # Early stopping to prevent overfitting\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True\n",
        "    ),\n",
        "\n",
        "    # Reduce learning rate when plateau\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=1e-7\n",
        "    ),\n",
        "\n",
        "    # Model checkpointing\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        'best_model.h5',\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        mode='max'\n",
        "    ),\n",
        "\n",
        "    # TensorBoard for visualization\n",
        "    tf.keras.callbacks.TensorBoard(\n",
        "        log_dir='./logs',\n",
        "        histogram_freq=1\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "PKapYPjw30yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "print(\"Starting training...\")\n",
        "history = training_model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=32,\n",
        "    epochs=50,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Training completed!\")"
      ],
      "metadata": {
        "id": "f81ATJlc3wvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test set\n",
        "test_loss, test_accuracy, test_precision, test_recall = training_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"\\nTest Results:\")\n",
        "print(f\"Loss: {test_loss:.4f}\")\n",
        "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Precision: {test_precision:.4f}\")\n",
        "print(f\"Recall: {test_recall:.4f}\")"
      ],
      "metadata": {
        "id": "-6gWj1B33tqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization of Training History"
      ],
      "metadata": {
        "id": "KXAafRlb4ZXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Training History Visualization ===\")\n",
        "\n",
        "# Plot training history\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Loss\n",
        "ax1.plot(history.history['loss'], label='Training Loss')\n",
        "ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
        "ax1.set_title('Training and Validation Loss')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "\n",
        "# Accuracy\n",
        "ax2.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "ax2.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "ax2.set_title('Training and Validation Accuracy')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "# Precision\n",
        "ax3.plot(history.history['precision'], label='Training Precision')\n",
        "ax3.plot(history.history['val_precision'], label='Validation Precision')\n",
        "ax3.set_title('Training and Validation Precision')\n",
        "ax3.set_xlabel('Epoch')\n",
        "ax3.set_ylabel('Precision')\n",
        "ax3.legend()\n",
        "ax3.grid(True)\n",
        "\n",
        "# Recall\n",
        "ax4.plot(history.history['recall'], label='Training Recall')\n",
        "ax4.plot(history.history['val_recall'], label='Validation Recall')\n",
        "ax4.set_title('Training and Validation Recall')\n",
        "ax4.set_xlabel('Epoch')\n",
        "ax4.set_ylabel('Recall')\n",
        "ax4.legend()\n",
        "ax4.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4u7jB1aJ4eEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lPh76zF93xNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate additional metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score"
      ],
      "metadata": {
        "id": "njhNk3j44toV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_pred_proba = training_model.predict(X_test)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
        "\n",
        "print(\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "vtM0FCEl4nC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g48VXLB34jPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC AUC Score\n",
        "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f\"ROC AUC Score: {auc_score:.4f}\")"
      ],
      "metadata": {
        "id": "xZX1Bcwh4iuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### End-to-End Regression: California Housing Dataset"
      ],
      "metadata": {
        "id": "tSz988JJJseq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 1: Load and Explore the Dataset\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ],
      "metadata": {
        "id": "rwXhrSbqJyQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "feature_names = housing.feature_names"
      ],
      "metadata": {
        "id": "ZUc66NAMJ5nI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset Information:\")\n",
        "print(f\"Number of samples: {X.shape[0]}\")\n",
        "print(f\"Number of features: {X.shape[1]}\")\n",
        "print(f\"Feature names: {feature_names}\")\n",
        "print(f\"Target range: ${y.min():.2f} - ${y.max():.2f} hundred thousands\")\n",
        "print(f\"Target mean: ${y.mean():.2f} hundred thousands\")"
      ],
      "metadata": {
        "id": "dlBohwBZJ8rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame for easier exploration\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(X, columns=feature_names)\n",
        "df['MedHouseVal'] = y"
      ],
      "metadata": {
        "id": "I71dhSO9KBqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFirst 5 rows of the dataset:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "-GPGUZ-4KCY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nBasic Statistics:\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "tbFU1Uk7KEkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 2: Essential Data Visualization\n",
        "\n",
        "print(\"\\n=== Essential Data Exploration ===\")\n",
        "\n",
        "# Create focused visualizations\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "# 1. Target Distribution\n",
        "axes[0, 0].hist(y, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "axes[0, 0].axvline(y.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: ${y.mean():.2f}K')\n",
        "axes[0, 0].set_xlabel('Median House Value (Thousands $)')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].set_title('Distribution of House Prices')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Correlation Matrix\n",
        "axes[0, 1].set_title('Feature Correlation Matrix')\n",
        "correlation_matrix = df.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
        "            fmt='.2f', square=True, ax=axes[0, 1])\n",
        "\n",
        "# 3. Most Important Feature vs Target\n",
        "most_correlated = correlation_matrix['MedHouseVal'].abs().sort_values(ascending=False).index[1]\n",
        "axes[0, 2].scatter(df[most_correlated], df['MedHouseVal'], alpha=0.5, s=10)\n",
        "axes[0, 2].set_xlabel(most_correlated)\n",
        "axes[0, 2].set_ylabel('Median House Value ($K)')\n",
        "axes[0, 2].set_title(f'Price vs {most_correlated}')\n",
        "axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Geographical Distribution\n",
        "scatter = axes[1, 0].scatter(df['Longitude'], df['Latitude'], c=df['MedHouseVal'],\n",
        "                            cmap='viridis', alpha=0.6, s=10)\n",
        "plt.colorbar(scatter, ax=axes[1, 0], label='Median House Value ($K)')\n",
        "axes[1, 0].set_xlabel('Longitude')\n",
        "axes[1, 0].set_ylabel('Latitude')\n",
        "axes[1, 0].set_title('Housing Prices by Location')\n",
        "\n",
        "# 5. Feature Distributions\n",
        "df[feature_names[:4]].boxplot(ax=axes[1, 1])\n",
        "axes[1, 1].set_title('Key Feature Distributions')\n",
        "axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# 6. Data Summary\n",
        "axes[1, 2].axis('off')\n",
        "summary_text = f\"\"\"\n",
        "Dataset Summary:\n",
        "---------------\n",
        "Samples: {len(df):,}\n",
        "Features: {len(feature_names)}\n",
        "Target: Median House Value\n",
        "\n",
        "Key Statistics:\n",
        "- Mean Price: ${y.mean():.2f}K\n",
        "- Price Range: ${y.min():.2f}K - ${y.max():.2f}K\n",
        "\n",
        "Top Correlated Features:\n",
        "\"\"\"\n",
        "top_features = correlation_matrix['MedHouseVal'].abs().sort_values(ascending=False)[1:4]\n",
        "for feature, corr in top_features.items():\n",
        "    summary_text += f\"- {feature}: {corr:.3f}\\n\"\n",
        "\n",
        "axes[1, 2].text(0.1, 0.9, summary_text, fontsize=10, verticalalignment='top',\n",
        "                bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.5))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Basic Statistical Analysis\n",
        "print(\"\\n=== Statistical Analysis ===\")\n",
        "print(\"Top 3 features correlated with target:\")\n",
        "for feature, corr in top_features.items():\n",
        "    print(f\"  {feature:15}: {corr:.4f}\")\n",
        "\n",
        "print(f\"\\nData Quality Check:\")\n",
        "print(f\"No missing values: {df.isnull().sum().sum() == 0}\")\n",
        "print(f\"Reasonable price range: ${y.min():.2f}K - ${y.max():.2f}K\")"
      ],
      "metadata": {
        "id": "GjEP90iwKhhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 3: Data Preprocessing and Splitting\n",
        "\n",
        "print(\"\\n=== Data Preprocessing ===\")\n",
        "\n",
        "# Handle any potential infinite values\n",
        "X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]:,} samples\")\n",
        "print(f\"Validation set: {X_val.shape[0]:,} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]:,} samples\")\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"\\nFeature scaling applied:\")\n",
        "print(f\"Training mean after scaling: {X_train_scaled.mean():.4f}\")\n",
        "print(f\"Training std after scaling: {X_train_scaled.std():.4f}\")"
      ],
      "metadata": {
        "id": "1rLZLJB3K_ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 4: Build Simple Neural Network Model\n",
        "\n",
        "print(\"\\n=== Building Simple Neural Network Model ===\")\n",
        "\n",
        "def create_simple_regression_model(input_dim):\n",
        "    \"\"\"Create a simple neural network for regression\"\"\"\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(16, activation='relu'),\n",
        "        tf.keras.layers.Dense(1)  # Linear activation for regression\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = create_simple_regression_model(X_train.shape[1])\n",
        "\n",
        "print(\"Model Architecture:\")\n",
        "model.summary()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='mse',  # Mean Squared Error for regression\n",
        "    metrics=['mae']  # Mean Absolute Error\n",
        ")\n",
        "\n",
        "print(\"Model compiled successfully!\")"
      ],
      "metadata": {
        "id": "W5uaFjsJL-oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 5: Model Training\n",
        "\n",
        "print(\"\\n=== Model Training ===\")\n",
        "\n",
        "# Define callbacks\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=15,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=10,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "EPOCHS = 100\n",
        "\n",
        "print(\"Starting model training...\")\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    batch_size=32,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(X_val_scaled, y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "print(\"Training completed!\")"
      ],
      "metadata": {
        "id": "PFC4VxIwMLHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 6: Model Evaluation\n",
        "\n",
        "print(\"\\n=== Model Evaluation ===\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_scaled, verbose=0).flatten()\n",
        "\n",
        "# Calculate metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "print(\"Model Performance Metrics:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"R² Score: {r2:.4f}\")\n",
        "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
        "\n",
        "# Business interpretation\n",
        "avg_price = y_test.mean()\n",
        "print(f\"\\nBusiness Interpretation:\")\n",
        "print(f\"Average house price in test set: ${avg_price:.2f}K\")\n",
        "print(f\"Typical prediction error: ±${mae:.2f}K\")\n",
        "print(f\"Error as percentage of average price: {(mae/avg_price)*100:.1f}%\")"
      ],
      "metadata": {
        "id": "dUTkC86DMUd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 7: Results Visualization\n",
        "\n",
        "print(\"\\n=== Results Visualization ===\")\n",
        "\n",
        "# Create comprehensive results visualization\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "# 1. Training History\n",
        "axes[0, 0].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
        "axes[0, 0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "axes[0, 0].set_title('Training History - Loss')\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('MSE Loss')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Predictions vs Actual\n",
        "axes[0, 1].scatter(y_test, y_pred, alpha=0.5, s=20)\n",
        "# Perfect prediction line\n",
        "min_val = min(y_test.min(), y_pred.min())\n",
        "max_val = max(y_test.max(), y_pred.max())\n",
        "axes[0, 1].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')\n",
        "axes[0, 1].set_xlabel('Actual Prices ($K)')\n",
        "axes[0, 1].set_ylabel('Predicted Prices ($K)')\n",
        "axes[0, 1].set_title('Predictions vs Actual Values')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Residual Analysis\n",
        "residuals = y_test - y_pred\n",
        "axes[0, 2].scatter(y_pred, residuals, alpha=0.5, s=20)\n",
        "axes[0, 2].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
        "axes[0, 2].set_xlabel('Predicted Prices ($K)')\n",
        "axes[0, 2].set_ylabel('Residuals (Actual - Predicted)')\n",
        "axes[0, 2].set_title('Residual Plot')\n",
        "axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Error Distribution\n",
        "axes[1, 0].hist(residuals, bins=30, alpha=0.7, color='lightcoral', edgecolor='black')\n",
        "axes[1, 0].axvline(residuals.mean(), color='red', linestyle='--', linewidth=2,\n",
        "                  label=f'Mean: {residuals.mean():.3f}')\n",
        "axes[1, 0].set_xlabel('Prediction Error')\n",
        "axes[1, 0].set_ylabel('Frequency')\n",
        "axes[1, 0].set_title('Error Distribution')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 5. Feature Importance\n",
        "first_layer_weights = model.layers[0].get_weights()[0]\n",
        "feature_importance = np.mean(np.abs(first_layer_weights), axis=1)\n",
        "\n",
        "axes[1, 1].barh(feature_names, feature_importance, color='lightgreen', alpha=0.7)\n",
        "axes[1, 1].set_xlabel('Average Absolute Weight')\n",
        "axes[1, 1].set_title('Feature Importance (First Layer)')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# 6. Performance Summary\n",
        "axes[1, 2].axis('off')\n",
        "performance_text = f\"\"\"\n",
        "Model Performance Summary:\n",
        "------------------------\n",
        "RMSE: ${rmse:.2f}K\n",
        "MAE:  ${mae:.2f}K\n",
        "R²:   {r2:.4f}\n",
        "MAPE: {mape:.2f}%\n",
        "\n",
        "Business Impact:\n",
        "---------------\n",
        "Average Price: ${avg_price:.2f}K\n",
        "Typical Error: ±${mae:.2f}K\n",
        "Accuracy: {100 - mape:.1f}%\n",
        "\n",
        "Interpretation:\n",
        "- Good for price estimation\n",
        "- {100 - mape:.1f}% accuracy on average\n",
        "- Useful for market analysis\n",
        "\"\"\"\n",
        "axes[1, 2].text(0.1, 0.9, performance_text, fontsize=10, verticalalignment='top',\n",
        "                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "997QZb28Mdu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('california_housing_model.h5')\n",
        "print(\"Model saved as 'california_housing_model.h5'\")"
      ],
      "metadata": {
        "id": "aIsYujXKNs-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create prediction function\n",
        "def predict_house_price(features):\n",
        "    \"\"\"\n",
        "    Predict house price for new data\n",
        "    features: numpy array of shape (n_samples, 8) with original feature values\n",
        "    \"\"\"\n",
        "    # Scale features\n",
        "    features_scaled = scaler.transform(features)\n",
        "\n",
        "    # Make prediction\n",
        "    predictions = model.predict(features_scaled, verbose=0)\n",
        "\n",
        "    return predictions.flatten()\n",
        "\n",
        "# Test prediction with sample data\n",
        "print(\"\\nSample Prediction Test:\")\n",
        "sample_house = np.array([[8.3252, 41.0, 6.984127, 1.023810, 322.0, 2.555556, 37.88, -122.23]])\n",
        "predicted_price = predict_house_price(sample_house)\n",
        "actual_price = 4.526  # Typical value for these features\n",
        "\n",
        "print(f\"Predicted price: ${predicted_price[0]:.2f}K\")\n",
        "print(f\"Typical actual price: ${actual_price:.2f}K\")\n",
        "print(f\"Prediction error: ${abs(predicted_price[0] - actual_price):.2f}K\")"
      ],
      "metadata": {
        "id": "JcWZVZqPNJf4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}